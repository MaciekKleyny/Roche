{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Headlines dataset - sarcasm detection**</font>\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "<b>Maciej Kleyny</b><br>\n",
    "m.kleyny@gazeta.pl<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_raw = []\n",
    "for line in open('Data/Graduate - HEADLINES dataset (2019-06).json', 'r'):\n",
    "    headers_raw.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
       "  'is_sarcastic': 0},\n",
       " {'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
       "  'is_sarcastic': 0},\n",
       " {'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
       "  'is_sarcastic': 1},\n",
       " {'headline': 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
       "  'is_sarcastic': 1},\n",
       " {'headline': 'j.k. rowling wishes snape happy birthday in the most magical way',\n",
       "  'is_sarcastic': 0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26709 26709 26709\n",
      "All keys are proper\n"
     ]
    }
   ],
   "source": [
    "# checking if all of the keys are the same and their amount equals headers' list shape\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for line in headers_raw:\n",
    "    \n",
    "    if list(line.keys())[0] == 'headline':\n",
    "        i += 1\n",
    "        \n",
    "    if list(line.keys())[1] == 'is_sarcastic':\n",
    "        j += 1\n",
    "        \n",
    "print(len(headers_raw), i, j)\n",
    "\n",
    "if len(headers_raw) == i ==j:\n",
    "    \n",
    "    print('All keys are proper')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Keys need to be investigated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing_f(list, test_size=0.15, val_size=0.15):\n",
    "# this function will take raw data as input, transform it and split it into train, validation and test data\n",
    "    \n",
    "    # extracting headlines and labels from dictionaries\n",
    "    header = [] \n",
    "    y = []\n",
    "\n",
    "    for line in list:\n",
    "    \n",
    "        header.append(line['headline'])\n",
    "        y.append(line['is_sarcastic'])\n",
    "        \n",
    "    # removing redundant symbols (punctuation, digits, initial spaces etc.) and lowering all letters\n",
    "    header_trimmed = []\n",
    "\n",
    "    for line in header:\n",
    "    \n",
    "        header_trimmed.append(line.translate(str.maketrans('', '', string.digits))\\\n",
    "        .translate(str.maketrans('', '', string.punctuation))\\\n",
    "        .strip()\\\n",
    "        .lower())\n",
    "    \n",
    "    # tokenizing every headline, i.e. dividing it into separate words\n",
    "    header_trimmed = [nltk.word_tokenize(line) for line in header_trimmed]\n",
    "    \n",
    "    # creating a set of english stop-words that will be removed from every headline\n",
    "    # as they're too common to add any value\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    \n",
    "    header_trimmed = [[word for word in line if word not in stop_words] for line in header_trimmed]\n",
    "    \n",
    "    # removing words endings to get rid of declination and conjugation\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    header_trimmed = [[stemmer.stem(word) for word in line] for line in header_trimmed]\n",
    "    \n",
    "    # putting words back together into a headline\n",
    "    header_trimmed = [' '.join(line) for line in header_trimmed]\n",
    "    \n",
    "#     del list\n",
    "    \n",
    "#     list = header_trimmed\n",
    "    \n",
    "    # creating train, validation and test subsets\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global X_val\n",
    "    global y_val\n",
    "    global X_test\n",
    "    global y_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(header_trimmed, y, test_size=test_size, random_state=1)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val \\\n",
    "    = train_test_split(X_train, y_train, test_size=val_size/(1-test_size), random_state=2)\n",
    "\n",
    "    print('This function preprocesses the raw data and splits it into train, validation and test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function preprocesses the raw data and splits it into train, validation and test data\n"
     ]
    }
   ],
   "source": [
    "Preprocessing_f(headers_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "In this part I'm going to grid-search for the best parameters combination for 3 models: Logistic Regression, Random Forest and Support Vector Machine. Next, I evaluate them based on their accuracy on the validation set, choose one and run it on the test set. The final step is comparing it to the 'dummy' model that predicts the most common class for every unseen observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed:  2.0min finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('count_vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'LogReg__C': [0.1, 0.5, 1],\n",
       "                         'count_vect__max_df': [0.5, 0.6, 0.7, 0.8],\n",
       "                         'count_vect__min_df': [0.005, 0.01, 0.02, 0.04],\n",
       "                         'count_vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "                    [('count_vect', CountVectorizer()),\n",
    "                    ('LogReg', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {}\n",
    "params['count_vect__ngram_range'] = [(1,1), (1,2), (1,3)]\n",
    "params['count_vect__max_df'] = [0.5, 0.6, 0.7, 0.8]\n",
    "params['count_vect__min_df'] = [0.005, 0.01, 0.02, 0.04]\n",
    "params['LogReg__C'] = [0.1, 0.5, 1]\n",
    "\n",
    "CV = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1)\n",
    "\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogReg__C': 0.5,\n",
       " 'count_vect__max_df': 0.5,\n",
       " 'count_vect__min_df': 0.005,\n",
       " 'count_vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6831773201390746"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression accuracy on the train set\n",
    "y_pred_train = CV.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6790616421262791"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression accuracy on the validation set\n",
    "y_pred_val = CV.predict(X_val)\n",
    "accuracy_score(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('count_vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'Forest__max_depth': [5, 10, 15],\n",
       "                         'Forest__n_estimators': [10, 20, 30],\n",
       "                         'count_vect__max_df': [0.5, 0.7],\n",
       "                         'count_vect__min_df': [0.005, 0.02],\n",
       "                         'count_vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline(\n",
    "                    [('count_vect', CountVectorizer()),\n",
    "                    ('Forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params2 = {}\n",
    "params2['count_vect__ngram_range'] = [(1,1), (1,2), (1,3)]\n",
    "params2['count_vect__max_df'] = [0.5, 0.7]\n",
    "params2['count_vect__min_df'] = [0.005, 0.02]\n",
    "params2['Forest__n_estimators'] = [10, 20, 30]\n",
    "params2['Forest__max_depth'] = [5, 10, 15]\n",
    "\n",
    "CV2 = GridSearchCV(pipeline2, params2, n_jobs=-1, verbose=1)\n",
    "\n",
    "CV2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Forest__max_depth': 15,\n",
       " 'Forest__n_estimators': 30,\n",
       " 'count_vect__max_df': 0.7,\n",
       " 'count_vect__min_df': 0.005,\n",
       " 'count_vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6737095480074886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest accuracy on the train set\n",
    "y_pred_train2 = CV2.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643374095333167"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest accuracy on the validation set\n",
    "y_pred_val2 = CV2.predict(X_val)\n",
    "accuracy_score(y_val, y_pred_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  5.5min finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('count_vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'SVM__degree': [2, 3], 'SVM__kernel': ['poly', 'rbf'],\n",
       "                         'count_vect__max_df': [0.5, 0.7],\n",
       "                         'count_vect__min_df': [0.005, 0.02],\n",
       "                         'count_vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3 = Pipeline(\n",
    "                    [('count_vect', CountVectorizer()),\n",
    "                    ('SVM', SVC())\n",
    "])\n",
    "\n",
    "params3 = {}\n",
    "params3['count_vect__ngram_range'] = [(1,1), (1,2), (1,3)]\n",
    "params3['count_vect__max_df'] = [0.5, 0.7]\n",
    "params3['count_vect__min_df'] = [0.005, 0.02]\n",
    "params3['SVM__kernel'] = ['poly', 'rbf']\n",
    "params3['SVM__degree'] = [2, 3]\n",
    "\n",
    "CV3 = GridSearchCV(pipeline3, params3, n_jobs=-1, verbose=1)\n",
    "\n",
    "CV3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM__degree': 2,\n",
       " 'SVM__kernel': 'rbf',\n",
       " 'count_vect__max_df': 0.5,\n",
       " 'count_vect__min_df': 0.005,\n",
       " 'count_vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6420433270928055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machine accuracy on the train set\n",
    "y_pred_train3 = CV3.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6456201647117544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machine accuracy on the validation set\n",
    "y_pred_val3 = CV3.predict(X_val)\n",
    "accuracy_score(y_val, y_pred_val3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation score:\n",
      "\n",
      "LogisticRegression accuracy: 0.68\n",
      "RandomForestClassifier accuracy: 0.66\n",
      "SupportVectorClassifier accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(f'''Accuracy on the validation score:\n",
    "\n",
    "LogisticRegression accuracy: {accuracy_score(y_val, y_pred_val).round(2)}\n",
    "RandomForestClassifier accuracy: {accuracy_score(y_val, y_pred_val2).round(2)}\n",
    "SupportVectorClassifier accuracy: {accuracy_score(y_val, y_pred_val3).round(2)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these scores I recommend Logistic Regression model with best_params:\n",
    "- regularization: 0.5\n",
    "\n",
    "and Count Vectorizer with parameters:\n",
    "- max_df: 0.5,\n",
    "- min_df: 0.005,\n",
    "- ngram_range: (1,2).\n",
    "\n",
    "\n",
    "Now I'm going to run the final check on the test subset using only 1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823059645620164"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model accuracy on the test set is...\n",
    "y_pred_test = CV.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6831773201390746"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# while the train set accuracy was...\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5672572997254804"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the 'dummy' model (assigning the most common group's label to every prediction) would give...\n",
    "np.mean(y_test == np.mean(y_train).round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the model I prepared is better than random and isn't overfitted at the same time. The accuracy isn't that great, but broader grid search might have helped. Also, dimensionality reduction would be a good idea to try."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
